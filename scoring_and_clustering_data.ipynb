{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import re\n",
    "from urllib.parse import quote\n",
    "import gc\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_of_data = \"./Data/Data_Scrapping_SE2026_Clean + Ditemukan.csv\"\n",
    "df = pd.read_csv(\n",
    "    path_of_data,\n",
    "    delimiter=';',\n",
    ")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[15:27], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Validasi\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by 'Validasi' column for rows where the value is 'Ditemukan'\n",
    "df[\"Validasi\"] = (\n",
    "    df[\"Validasi\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.replace(\"\\\\\", \"\", regex=False)\n",
    "    .str.replace('\"', \"\", regex=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Validasi\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df[\"Validasi\"] == \"Ditemukan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_filtered.describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Membersihkan dan normalisasi teks untuk perbandingan\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    # Hapus karakter khusus tapi pertahankan spasi\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Hapus spasi berlebih\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(query, place_name, address):\n",
    "    \"\"\"Menghitung similarity score antara query dengan place_name + address\"\"\"\n",
    "    query_clean = clean_text(query)\n",
    "    place_clean = clean_text(place_name)\n",
    "    address_clean = clean_text(address)\n",
    "    \n",
    "    # Gabungkan place name dan address\n",
    "    combined = f\"{place_clean} {address_clean}\"\n",
    "    \n",
    "    # Hitung similarity menggunakan SequenceMatcher\n",
    "    similarity = SequenceMatcher(None, query_clean, combined).ratio()\n",
    "    \n",
    "    # Berikan bonus jika place_name sangat mirip dengan query\n",
    "    place_similarity = SequenceMatcher(None, query_clean, place_clean).ratio()\n",
    "    \n",
    "    # Weighted score: 60% dari combined similarity, 40% dari place similarity\n",
    "    final_score = (similarity * 0.6) + (place_similarity * 0.4)\n",
    "    \n",
    "    return final_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(input_file):\n",
    "    \"\"\"Memproses CSV dan melakukan deduplikasi berdasarkan kecocokan query\"\"\"\n",
    "    \n",
    "    print(f\"Melakukan cleaning......................................\\n\")\n",
    "    df = pd.DataFrame(input_file)\n",
    "    def clean_text(x):\n",
    "        if isinstance(x, str):\n",
    "            return (\n",
    "                x.replace('', '')\n",
    "                .replace('\\n', ' ')\n",
    "                .replace('\\r', ' ')\n",
    "                .strip()\n",
    "            )\n",
    "        return x\n",
    "    df_res = df.map(clean_text)\n",
    "    # print(df)\n",
    "    \n",
    "    # Pastikan kolom yang diperlukan ada\n",
    "    required_cols = ['idsbr', 'Query', 'Actual Place Name', 'Address']\n",
    "    missing_cols = [col for col in required_cols if col not in df_res.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Error: Kolom yang hilang: {missing_cols}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Total baris: {len(df)}\")\n",
    "    \n",
    "    # Tambahkan kolom untuk similarity score dan validasi\n",
    "    df_res['similarity_score'] = 0.0\n",
    "    df_res['Validasi'] = 'Tidak Ditemukan'\n",
    "    \n",
    "    # Hitung similarity score untuk setiap baris \n",
    "    for idx, row in df_res.iterrows():\n",
    "        score = calculate_similarity(\n",
    "            row['Query'],\n",
    "            row['Actual Place Name'],\n",
    "            row['Address']\n",
    "        )\n",
    "        if score > 0.6:\n",
    "            df_res.at[idx, 'similarity_score'] = score\n",
    "\n",
    "    # print(df)\n",
    "    \n",
    "    # Group by idsbr untuk mencari winner\n",
    "    grouped = df_res.groupby('idsbr')\n",
    "    \n",
    "    processed_rows = []\n",
    "    \n",
    "    for idsbr, group in grouped:\n",
    "        if pd.isna(idsbr) or str(idsbr).strip() == '':\n",
    "            # Jika idsbr kosong, tandai sebagai tidak ditemukan\n",
    "            for idx, row in group.iterrows():\n",
    "                row_dict = row.to_dict()\n",
    "                row_dict['Validasi'] = 'Tidak Ditemukan'\n",
    "\n",
    "                processed_rows.append(row_dict)\n",
    "            continue\n",
    "        \n",
    "        # Urutkan berdasarkan similarity score (descending)\n",
    "        sorted_group = group.sort_values('similarity_score', ascending=False)\n",
    "        \n",
    "        # Ambil winner (score tertinggi)\n",
    "        winner_idx = sorted_group.index[0]\n",
    "        \n",
    "        for idx, row in sorted_group.iterrows():\n",
    "            row_dict = row.to_dict()\n",
    "            \n",
    "            if idx == winner_idx:\n",
    "                # Ini adalah winner\n",
    "                row_dict['Validasi'] = 'Ditemukan'\n",
    "                row_dict['idsbr'] = idsbr\n",
    "            else:\n",
    "                # Ini adalah loser, kosongkan idsbr\n",
    "                row_dict['Validasi'] = 'Tidak Ditemukan'\n",
    "            \n",
    "            processed_rows.append(row_dict)\n",
    "\n",
    "\n",
    "    # Buat dataframe baru dari hasil\n",
    "    result_df = pd.DataFrame(processed_rows)\n",
    "    # print(result_df)\n",
    "    \n",
    "    # Hapus kolom similarity_score (kolom temporary)\n",
    "    result_df = result_df.drop('similarity_score', axis=1)\n",
    "    \n",
    "    # Urutkan ulang kolom agar Validasi di akhir\n",
    "    cols = [col for col in result_df.columns if col != 'Validasi']\n",
    "    cols.append('Validasi')\n",
    "    result_df = result_df[cols]\n",
    "    \n",
    "    kolom_utama = [\n",
    "                'idsbr', 'Query', 'Actual Place Name', 'Category', 'Rating',\n",
    "                'Address', 'Phone Number', 'Website', 'Latitude', 'Longitude',\n",
    "                'Status', 'Open Status', 'Operation Hours'\n",
    "    ]\n",
    "                # Ambil kolom utama yang benar-benar ada di DataFrame\n",
    "    kolom_utama_ada = [c for c in kolom_utama if c in result_df.columns]\n",
    "\n",
    "                # Ambil kolom tambahan (selain kolom utama)\n",
    "    kolom_tambahan = [c for c in result_df.columns if c not in kolom_utama_ada]\n",
    "\n",
    "                # Susun ulang kolom\n",
    "    result_df = result_df[kolom_utama_ada + kolom_tambahan]\n",
    "    # Simpan ke file output\n",
    "\n",
    "    # Tampilkan statistik\n",
    "    return result_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorring_data (df_input:pd.DataFrame):\n",
    "    def clean_text(x):\n",
    "        if isinstance(x, str):\n",
    "            return (\n",
    "                x.replace('', '')\n",
    "                .replace('\\n', ' ')\n",
    "                .replace('\\r', ' ')\n",
    "                .strip()\n",
    "            )\n",
    "        return x\n",
    "    df_res = df_input.map(clean_text)\n",
    "    # print(df)\n",
    "    \n",
    "    # Pastikan kolom yang diperlukan ada\n",
    "    required_cols = ['idsbr', 'Query', 'Actual Place Name', 'Address']\n",
    "    missing_cols = [col for col in required_cols if col not in df_res.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Error: Kolom yang hilang: {missing_cols}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Total baris: {len(df)}\")\n",
    "\n",
    "    required_cols = ['idsbr', 'Query', 'Actual Place Name', 'Address']\n",
    "    missing_cols = [col for col in required_cols if col not in df_res.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Error: Kolom yang hilang: {missing_cols}\")\n",
    "        return\n",
    "    \n",
    "    # Hitung similarity score untuk setiap baris\n",
    "    for idx, row in df_res.iterrows():\n",
    "        score = calculate_similarity(\n",
    "            row['Query'],\n",
    "            row['Actual Place Name'],\n",
    "            row['Address']\n",
    "        )\n",
    "        df_res.at[idx, 'similarity_score'] = score\n",
    "    # df_result = df_res\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering by Country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batas koordinat Surabaya (Update Final 2026)\n",
    "SURABAYA_BOUNDS = {\n",
    "    'lat_min': -7.36,  \n",
    "    'lat_max': -7.15,  \n",
    "    'lon_min': 112.59, \n",
    "    'lon_max': 112.88  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bersihkan_dan_konversi(nilai, tipe='lat'):\n",
    "    \"\"\"Membersihkan format titik ganda dan konversi ke float\"\"\"\n",
    "    try:\n",
    "        if pd.isna(nilai): return None\n",
    "        \n",
    "        # Ubah ke string dan bersihkan karakter non-numerik kecuali minus dan titik\n",
    "        s = re.sub(r'[^0-9\\.\\-]', '', str(nilai))\n",
    "        \n",
    "        # Jika ada lebih dari satu titik, ambil semua angka dan format ulang\n",
    "        if s.count('.') > 1:\n",
    "            digits = s.replace('.', '').replace('-', '')\n",
    "            sign = \"-\" if \"-\" in s else \"\"\n",
    "            if tipe == 'lat':\n",
    "                # Asumsi Latitude Surabaya dimulai dengan -7...\n",
    "                return float(sign + digits[0] + \".\" + digits[1:])\n",
    "            else:\n",
    "                # Asumsi Longitude Surabaya dimulai dengan 112...\n",
    "                # Menangani kasus '1.127...' atau '112.7...'\n",
    "                if digits.startswith('112'):\n",
    "                    return float(digits[:3] + \".\" + digits[3:])\n",
    "                else:\n",
    "                    return float(digits[:3] + \".\" + digits[3:])\n",
    "        \n",
    "        return float(s)\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cek_lokasi_surabaya(lat_raw, lon_raw):\n",
    "    \"\"\"Mengecek apakah koordinat berada di dalam batas Surabaya\"\"\"\n",
    "    lat = bersihkan_dan_konversi(lat_raw, 'lat')\n",
    "    lon = bersihkan_dan_konversi(lon_raw, 'lon')\n",
    "    \n",
    "    if lat is None or lon is None:\n",
    "        return \"error_koordinat\"\n",
    "    \n",
    "    # Normalisasi otomatis jika angka meledak (misal -72.5 menjadi -7.25)\n",
    "    if lat < -10: lat = lat / 10\n",
    "    if lon > 1000: lon = lon / 10\n",
    "    \n",
    "    is_lat_in = SURABAYA_BOUNDS['lat_min'] <= lat <= SURABAYA_BOUNDS['lat_max']\n",
    "    is_lon_in = SURABAYA_BOUNDS['lon_min'] <= lon <= SURABAYA_BOUNDS['lon_max']\n",
    "    \n",
    "    if is_lat_in and is_lon_in:\n",
    "        return \"disurabaya\"\n",
    "    else:\n",
    "        return \"tidak disurabaya\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ambil data yang sudah di bersihkan \n",
    "# df = df_filtered\n",
    "\n",
    "# #scoring process\n",
    "# df_res = scorring_data(df)\n",
    "# df_res.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res['similarity_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EKSEKUSI DATA ===\n",
    "file_path = \"./Data/df_res_score.csv\"\n",
    "\n",
    "try:\n",
    "    # Membaca file dengan pemisah ;\n",
    "    df = pd.read_csv(file_path, delimiter=',', low_memory=False)\n",
    "\n",
    "    # # 1. Hapus kolom Column1 sampai Column12 jika ada\n",
    "    # cols_to_drop = [f'Column{i}' for i in range(1, 13) if f'Column{i}' in df.columns]\n",
    "    # df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # 2. Tambahkan kolom status_lokasi dengan fungsi yang sudah diperbaiki\n",
    "    df['status_lokasi'] = df.apply(\n",
    "        lambda row: cek_lokasi_surabaya(row['Latitude'], row['Longitude']), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 3. Simpan hasil\n",
    "    output_path = \"./DATA/clean_final_sby_all_score.csv\"\n",
    "    df.to_csv(output_path, sep=';', index=False)\n",
    "\n",
    "    print(\"=== LAPORAN PROSES 2026 ===\")\n",
    "    print(f\"Total Data: {len(df)}\")\n",
    "    print(f\"Distribusi:\\n{df['status_lokasi'].value_counts()}\")\n",
    "    \n",
    "    # Tes bukti perbaikan untuk data yang Anda tanyakan\n",
    "    print(\"\\nTes Data Error (contoh -72.527.579):\")\n",
    "    print(f\"Hasil: {cek_lokasi_surabaya('-72.527.579', '112.735.948')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Terjadi kesalahan: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grap a data with spesific longtitude \n",
    "df = pd.read_csv('./Data/clean_final_sby_all_score.csv',delimiter=';')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[df['status_lokasi'] == 'disurabaya' and df['similarity_score'] > 0.6]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
